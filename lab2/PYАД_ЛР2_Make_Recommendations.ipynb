{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Данные"
      ],
      "metadata": {
        "id": "b36veOGcKbDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise\n",
        "\n",
        "!gdown 1Hliaee7Y584-7lMoGeGjGabRRubzdoYn\n",
        "!gdown 1JYpk5GTzK7GWT3mtDb9fNiwaVTzk8BBy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split as surprise_train_test_split, GridSearchCV\n",
        "from surprise import accuracy\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AEw2kCzx4fn",
        "outputId": "4410e567-ca71-4bb0-cfb2-6ae68f8ee0f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/154.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357290 sha256=877142c821c7b39a34e24de0dd02925f53ef266b37e072d00c770980c531be86\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Hliaee7Y584-7lMoGeGjGabRRubzdoYn\n",
            "To: /content/Ratings.csv\n",
            "100% 22.6M/22.6M [00:00<00:00, 86.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JYpk5GTzK7GWT3mtDb9fNiwaVTzk8BBy\n",
            "To: /content/Books.csv\n",
            "100% 73.3M/73.3M [00:00<00:00, 170MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтение данных"
      ],
      "metadata": {
        "id": "B5JaeomHyjUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books = pd.read_csv(\"Books.csv\", encoding='utf-8', low_memory=False)\n",
        "ratings = pd.read_csv(\"Ratings.csv\", encoding='utf-8', low_memory=False)"
      ],
      "metadata": {
        "id": "6d5CKuegykSP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обработка данных"
      ],
      "metadata": {
        "id": "UPEQ3V7iKcsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Приводим год к числу, убираем некорректные"
      ],
      "metadata": {
        "id": "PrjsDeBm2yBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books[\"Year-Of-Publication\"] = pd.to_numeric(books[\"Year-Of-Publication\"], errors='coerce')\n",
        "books = books[(books[\"Year-Of-Publication\"] >= 1) & (books[\"Year-Of-Publication\"] <= 2024)]"
      ],
      "metadata": {
        "id": "06ny0z-u2y59"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Убираем пропуски по обязательным для нас столбцам"
      ],
      "metadata": {
        "id": "hqq0VL0X2zvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books = books.dropna(subset=[\"Book-Author\", \"Publisher\", \"Book-Title\"])"
      ],
      "metadata": {
        "id": "YE9IFxBK21bh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Удаляем колонки с адресами картинок (не нужны)"
      ],
      "metadata": {
        "id": "22p6ndjV22XV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_drop = [\"Image-URL-S\", \"Image-URL-M\", \"Image-URL-L\"]\n",
        "books.drop(columns=cols_to_drop, inplace=True, errors='ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kPf_IM623ZT",
        "outputId": "cd505001-f534-40fc-eb68-f6c0c2586612"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-5d171570fc3e>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  books.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем, что рейтинг = 0 -> пользователь не оценивал книгу (убираем из train)"
      ],
      "metadata": {
        "id": "U1T6g_PN3MRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = ratings[ratings[\"Book-Rating\"] > 0].copy()"
      ],
      "metadata": {
        "id": "AnTnjYDc3Ncb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Убираем книги/пользователей, которым/которыми поставлена только 1 оценка"
      ],
      "metadata": {
        "id": "BEZD2QpK3Pki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_counts = ratings[\"ISBN\"].value_counts()\n",
        "valid_books = book_counts[book_counts > 1].index\n",
        "user_counts = ratings[\"User-ID\"].value_counts()\n",
        "valid_users = user_counts[user_counts > 1].index\n",
        "\n",
        "ratings = ratings[ratings[\"ISBN\"].isin(valid_books)]\n",
        "ratings = ratings[ratings[\"User-ID\"].isin(valid_users)]"
      ],
      "metadata": {
        "id": "7Tpc75ui3QrR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сужаем таблицу books до тех ISBN, которые остались после фильтрации"
      ],
      "metadata": {
        "id": "WgRhjU-w3UIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books = books[books[\"ISBN\"].isin(ratings[\"ISBN\"].unique())]"
      ],
      "metadata": {
        "id": "_Ri2_CFX3VIR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение SVD"
      ],
      "metadata": {
        "id": "y3aBqtLtQrTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset.load_from_df(\n",
        "    ratings[[\"User-ID\", \"ISBN\", \"Book-Rating\"]],\n",
        "    Reader(rating_scale=(1, 10))\n",
        ")\n",
        "\n",
        "trainset, testset = surprise_train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "aRWnA4xJ3apV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подберём гиперпараметры пошире, чтобы добиться MAE < 1.3"
      ],
      "metadata": {
        "id": "vMJCPumR3bkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_factors': [50, 100, 150, 200],\n",
        "    'lr_all':    [0.002, 0.005, 0.007, 0.01],\n",
        "    'reg_all':   [0.02, 0.05, 0.1, 0.2]\n",
        "}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['mae'], cv=3, n_jobs=-1, joblib_verbose=0)\n",
        "gs.fit(data)\n",
        "\n",
        "best_params = gs.best_params['mae']\n",
        "print(\"Best params SVD:\", best_params)\n",
        "\n",
        "model_svd = SVD(\n",
        "    n_factors=best_params['n_factors'],\n",
        "    lr_all=best_params['lr_all'],\n",
        "    reg_all=best_params['reg_all'],\n",
        "    random_state=42\n",
        ")\n",
        "model_svd.fit(trainset)\n",
        "\n",
        "predictions = model_svd.test(testset)\n",
        "mae_svd = accuracy.mae(predictions)\n",
        "print(\"SVD MAE on our test:\", mae_svd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQC54v_N3eRN",
        "outputId": "85c6f5db-1180-47ed-d2bb-1b8e4e3657ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params SVD: {'n_factors': 50, 'lr_all': 0.007, 'reg_all': 0.1}\n",
            "MAE:  1.2460\n",
            "SVD MAE on our test: 1.2459537247522734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраним обученную модель SVD"
      ],
      "metadata": {
        "id": "nscgXelN3icD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"svd.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model_svd, f)"
      ],
      "metadata": {
        "id": "NAuXRa-oQtpf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение линейной регрессии\n",
        "\n"
      ],
      "metadata": {
        "id": "II6PZfHWR21O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем для каждой книги средний рейтинг"
      ],
      "metadata": {
        "id": "8c3IR_BG3kOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_mean_ratings = ratings.groupby(\"ISBN\")[\"Book-Rating\"].mean().reset_index(name=\"mean_rating\")\n",
        "books_merge = pd.merge(books, book_mean_ratings, on=\"ISBN\", how=\"inner\")"
      ],
      "metadata": {
        "id": "tazitJDF3lDW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Год -> числовая колонка (уже приведен выше), но дальше может понадобиться масштабирование"
      ],
      "metadata": {
        "id": "TKt6GTDC3mX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "year_col = books_merge[\"Year-Of-Publication\"].fillna(0).astype(float)"
      ],
      "metadata": {
        "id": "qDZ7DXFT3nwb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Автор и Издатель переводим в ID"
      ],
      "metadata": {
        "id": "QNs2HbkJ3rCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "authors_unique = books_merge[\"Book-Author\"].unique().tolist()\n",
        "authors_dict = {a: i for i, a in enumerate(authors_unique)}\n",
        "author_id_col = books_merge[\"Book-Author\"].map(authors_dict).fillna(-1).astype(int)\n",
        "\n",
        "publishers_unique = books_merge[\"Publisher\"].unique().tolist()\n",
        "publishers_dict = {p: i for i, p in enumerate(publishers_unique)}\n",
        "publisher_id_col = books_merge[\"Publisher\"].map(publishers_dict).fillna(-1).astype(int)"
      ],
      "metadata": {
        "id": "pI3_yMB63sv8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF для названий (макс 1000 фич)"
      ],
      "metadata": {
        "id": "ThYDuskM3t8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=1000)\n",
        "title_vectors = vectorizer.fit_transform(books_merge[\"Book-Title\"].fillna(\"\"))"
      ],
      "metadata": {
        "id": "uCgLZGcr3vpV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Собираем X так, чтобы было ровно 1003 колонки: [year, author_id, publisher_id] + 1000 tf-idf"
      ],
      "metadata": {
        "id": "-fJvXQDw3xZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_data = pd.DataFrame({\n",
        "    \"year\": year_col.values,\n",
        "    \"author_id\": author_id_col.values,\n",
        "    \"publisher_id\": publisher_id_col.values\n",
        "})"
      ],
      "metadata": {
        "id": "w_cFXupN3ykD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прогоняем через StandardScaler, чтобы нормировать только эти три числовых признака"
      ],
      "metadata": {
        "id": "FETy07_730_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "num_data_scaled = scaler.fit_transform(num_data)"
      ],
      "metadata": {
        "id": "-dW4xA3332Om"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее конкатенируем с TF-IDF (shape=(N,1000)) => итого (N, 1003)"
      ],
      "metadata": {
        "id": "MvKNqI_n35WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "num_data_sparse = csr_matrix(num_data_scaled)\n",
        "X = hstack([num_data_sparse, title_vectors], format='csr')  # (N, 3 + 1000) = (N, 1003)\n",
        "y = books_merge[\"mean_rating\"].values"
      ],
      "metadata": {
        "id": "lEX73T9H3326"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Делим на train/test (для локальной оценки), обучаем SGDRegressor"
      ],
      "metadata": {
        "id": "qLwM6Oy-38ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "linreg = SGDRegressor(\n",
        "    random_state=42,\n",
        "    max_iter=1000,\n",
        "    tol=1e-3\n",
        ")\n",
        "linreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = linreg.predict(X_test)\n",
        "mae_linreg = mean_absolute_error(y_test, y_pred)\n",
        "print(\"LinReg MAE on our test:\", mae_linreg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEPKsoQ6392p",
        "outputId": "931b5c0c-362a-40cd-fef0-6335e16d5df7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinReg MAE on our test: 0.9967102016706337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраняем всё"
      ],
      "metadata": {
        "id": "AukNA-9e3_JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"linreg.pkl\", \"wb\") as f:\n",
        "    pickle.dump(linreg, f)\n",
        "\n",
        "with open(\"scaler.pkl\", \"wb\") as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vectorizer, f)\n",
        "\n",
        "with open(\"authors_dict.pkl\", \"wb\") as f:\n",
        "    pickle.dump(authors_dict, f)\n",
        "\n",
        "with open(\"publishers_dict.pkl\", \"wb\") as f:\n",
        "    pickle.dump(publishers_dict, f)"
      ],
      "metadata": {
        "id": "9x_hh8VY4BSt"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}