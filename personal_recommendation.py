# -*- coding: utf-8 -*-
"""Копия блокнота "PYАД ЛР2: Make Recommendations.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mI3bXwF3s2ZM669Mzlc4hD6zImrcWZOU

## Данные

В этой лабораторной работе будем работать с [датасетом](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset), предназначенным для обучения алгоритма рекомендаций книг.

Для рекомендаций нам понадобятся таблицы `Books.csv` и `Ratings.scv`. Файл с рейтингами можно найти в папке с лабораторной работой на гитхабе. Файл с описаниями книг слишком большой, поэтому он располагается только по ссылке:
1. Файл с рейтингами (такой же, как в гитхабе): https://drive.google.com/file/d/1Hliaee7Y584-7lMoGeGjGabRRubzdoYn/view?usp=sharing
2. Файл с книгами:  https://drive.google.com/file/d/1JYpk5GTzK7GWT3mtDb9fNiwaVTzk8BBy/view?usp=sharing
"""

import pandas as pd

!gdown 1Hliaee7Y584-7lMoGeGjGabRRubzdoYn
!gdown 1JYpk5GTzK7GWT3mtDb9fNiwaVTzk8BBy

"""Посмотрим на таблицу `Ratings`."""

ratings = pd.read_csv("Ratings.csv")
ratings.head()

ratings.info()

ratings.describe().T

"""Как распределяются рейтинги?"""

import matplotlib.pyplot as plt
import seaborn as sns

sns.set_context("notebook")
sns.set_style("whitegrid")

ratings["Book-Rating"].hist()
plt.xlabel("Rating value")
plt.ylabel("Rating count")
plt.show()

"""Теперь посмотрим на таблицу `Books`."""

books = pd.read_csv("Books.csv")
books.head()

books.info()

"""- Есть немножко пропусков.
- Проверим уязвимую часть данных – года – на адекватность.
"""

books["Year-Of-Publication"].value_counts().sort_values(ascending=True)[:10]

"""Есть года, которые еще не наступили...

Проверим, есть ли строковые данные в столбце с годом (потому что `info()` назвал тип данных столбца `object`).
"""

books[books["Year-Of-Publication"].map(str).str.match("[^0-9]")]

"""В трех строках пропущен автор, из-за чего смещены данные. Автор либо пропущен, либо склеен с названием. Надо проверить.

В сводке написано, что часть авторов и издателей провущена. Проверим, так ли это.
"""

books[(books["Book-Author"].isnull()) | (books["Publisher"].isnull())]

"""Да, это так. Основные проблемы с данными выявили. Пора их исправлять и приступать к созданию рекомендаций.

## План анализа данных

1. Обработать данные, т.к. в данных есть несколько небольших проблем:
  1. В паре строк в таблице `Books.scv` значения столбцов сдвинуты вправо, а еще есть года, которые еще не наступили.
  2. В нескольких строках в таблице `Books.scv` есть пропуски, а также для рекомендаций в рамках лабораторной не понадобятся ссылки на картинки с обложкой.
  3. Не будем использовать для обучения записи с рейтинг равным 0 из таблицы `Ratings.scv`. Считаем, что 0 означает, что пользователь еще не оценивал книгу, но проявил к ней какой-то интерес.
  4. Не будем использовать для обучения алгоритмов те книги, которым оценка поставлена всего 1 раз. Пользователей, оценивших всего одну книгу тоже брать в расчет не будем (хотя это на самом деле будет не сильно сказываться на обобщающей способности алгоритмов, можете сами проверить).
  5. Пункты 1-4 необходимы и достаточны для выполнения всех задач. Но можно сделать более глубокую обработку.
2. Обучить [SVD](https://surprise.readthedocs.io/en/stable/getting_started.html) на следующих записях: у книги есть хотя бы одна оценка, пользователь оценил хотя бы одну книгу.
   - МАЕ должно быть ниже 1.3 (для этого есть тест)
   - **Сохранить модель.**
3. Научить линейную регрессию ([SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)) предсказывать средний рейтинг книги по следующим столбцам: автор, издатель, год издания, векторизованное название (для векторизации можно использовать [tf-idf](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting), [word2vec](https://radimrehurek.com/gensim/models/word2vec.html) или более сложный алгоритм. Для достижения требуемой тестом точности достаточно будет tf-idf. Собрав полностью датасет, не забудьте нормализовать данные ([StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)).
   - МАЕ должно быть ниже 1.5 (для этого есть тест)
   - **Сохранить модель.**
4. В файле `personal_recommendation.py` создайте рекомендацию для пользователя, у которого в исходном датасете было больше всего 0 среди рейтингов книг.
   Алгоритм такой:
   1. Находим нужного пользователя.
   2. Делаем предсказание SVD для книг, которым он "поставил" 0.
   3. Берем те книги, для которых предсказали рейтинг не ниже 8. Считаем, что 8 означет, что книга ему точно понравится.
   4. Делаем предсказание LinReg для этих же книг.
   5. Сортируем полученный на шаге 3 список по убыванию рейтинга линейной модели.
   6. В конце файла комментарием записываем полученную рекомендацию.

- То есть идея в том, чтобы сделать для пользователя индивидуальную рекомендацию, показывая в начале списка те книги, которые в целом могли бы иметь высокий рейтинг.
- Обязательно сохраняйте готовую модель и добавляйте ее в свой репозиторий, потому что файл с сохраненной моделью используется в тестах.

## Куда сдавать?

По инструкции в гитхаб – https://shy-question-39d.notion.site/1150ea832e418032bfc3d3e827c380fb?pvs=74

- К этой работе есть два теста – на качество получившихся моделей.
- Пул-реквест нужно сделать в ветку `lab2`.
- Можно загрузить в гитхаб файлы с реализацией по шаблону (шаблон можно дополнять и изменять под себя) или подготовить колаб с решением. Главное – сохранить модели, тесты проверяют их.

> Будьте внимательны! На гитхабе в ветке `main` обновился файл `pyad.yml`.

**Устная защита работ не требуется, но вам могут быть заданы вопросы прямо в вашем пул-реквесте!**
"""

!pip install scikit-surprise

# Импорт необходимых библиотек
import pandas as pd
import numpy as np
import pickle
from surprise import Dataset, Reader, SVD, accuracy
from surprise.model_selection import train_test_split as surprise_train_test_split, GridSearchCV
from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split

# Загрузка данных
books = pd.read_csv('Books.csv', encoding='latin-1', low_memory=False)
ratings = pd.read_csv('Ratings.csv')

# Обработка данных Books.csv
books.rename(columns={'Book-Title': 'title', 'Book-Author': 'author', 'Publisher': 'publisher', 'Year-Of-Publication': 'year'}, inplace=True)
books['year'] = pd.to_numeric(books['year'], errors='coerce')  # Преобразуем годы в числовой формат
books = books[(books['year'] <= 2024) & (books['year'] > 0)]  # Удаляем некорректные и будущие годы
books.drop(columns=['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], inplace=True, errors='ignore')  # Удаляем ссылки на обложки
books.dropna(subset=['author', 'publisher', 'year', 'title'], inplace=True)  # Удаляем строки с пропусками

# Обработка данных Ratings.csv
ratings.rename(columns={'User-ID': 'user_id', 'ISBN': 'item_id', 'Book-Rating': 'rating'}, inplace=True)
ratings = ratings[ratings['rating'] > 0]  # Исключаем рейтинги 0

# Исключаем книги с единственной оценкой и пользователей, оценивших только одну книгу
book_counts = ratings['item_id'].value_counts()
user_counts = ratings['user_id'].value_counts()
ratings = ratings[ratings['item_id'].isin(book_counts[book_counts > 1].index)]
ratings = ratings[ratings['user_id'].isin(user_counts[user_counts > 1].index)]

# Подготовка данных для модели SVD
reader = Reader(rating_scale=(1, 10))
svd_data = Dataset.load_from_df(ratings[['user_id', 'item_id', 'rating']], reader)
trainset = svd_data.build_full_trainset()

# Настройка параметров SVD
param_grid = {
    'n_factors': [50, 100],
    'n_epochs': [20, 30],
    'lr_all': [0.005, 0.01],
    'reg_all': [0.02, 0.1]
}
gs = GridSearchCV(SVD, param_grid, measures=['mae'], cv=3)
gs.fit(svd_data)
print(gs.best_params['mae'])

# Обучение лучшей модели SVD
svd = gs.best_estimator['mae']
svd.fit(trainset)

# Тестирование модели SVD
trainset, testset = surprise_train_test_split(svd_data, test_size=0.1)
predictions = svd.test(testset)
mae_svd = accuracy.mae(predictions)
print(f"MAE для SVD модели: {mae_svd}")

# Сохранение модели SVD
with open('svd.pkl', 'wb') as f:
    pickle.dump(svd, f)

# Подготовка данных для линейной регрессии
merged_data = ratings.merge(books, left_on='item_id', right_on='ISBN')
vectorizer = TfidfVectorizer(max_features=100)
vectorized_titles = vectorizer.fit_transform(merged_data['title'].fillna('')).toarray()

# Преобразуем категориальные признаки в числовые (factorize для каждого столбца)
categorical_features = merged_data[['author', 'publisher', 'year']].fillna('')
categorical_encoded = pd.DataFrame({
    col: pd.factorize(categorical_features[col])[0]
    for col in categorical_features
})

# Объединяем категориальные признаки и векторизованные названия
features = pd.concat(
    [categorical_encoded, pd.DataFrame(vectorized_titles)],
    axis=1
)

# Обеспечиваем, что все имена столбцов строковые
features.columns = features.columns.astype(str)

scaler = StandardScaler()
X = scaler.fit_transform(features)
y = merged_data['rating']

# Разделение данных на тренировочную и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Обучение модели линейной регрессии (SGDRegressor)
sgd = SGDRegressor(max_iter=1000, tol=1e-3)
sgd.fit(X_train, y_train)

# Тестирование модели линейной регрессии
predictions_sgd = sgd.predict(X_test)
mae_sgd = mean_absolute_error(y_test, predictions_sgd)
print(f"MAE для линейной регрессии (SGD): {mae_sgd}")

# Сохранение модели линейной регрессии
with open('linreg.pkl', 'wb') as f:
    pickle.dump(sgd, f)


# Сохранение тестовых данных для тестирования
svd_test = pd.DataFrame(
    [[pred.uid, pred.iid, pred.r_ui] for pred in predictions],
    columns=['user_id', 'item_id', 'rating']
)
svd_test.to_csv('svd_test.csv', index=False)

linreg_test = pd.DataFrame(X_test, columns=[f'feature_{i}' for i in range(X_test.shape[1])])
linreg_test['y'] = y_test.reset_index(drop=True)
linreg_test.to_csv('linreg_test.csv', index=False)

print("Все модели обучены и сохранены. Файлы для тестирования созданы.")

from google.colab import files

files.download('svd.pkl')  # Загрузка модели SVD
files.download('linreg.pkl')  # Загрузка модели линейной регрессии
files.download('svd_test.csv')  # Загрузка тестового файла SVD
files.download('linreg_test.csv')  # Загрузка тестового файла линейной регрессии